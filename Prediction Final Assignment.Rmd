---
title: "Machine Learning Prediction Assignment"
author: "Mark Cichonski"
date: "May 22, 2016"
output: html_document
---

#1. Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

#2. Source Data

The training data for this project are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:

https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

#3.Goal

The goal of this project is to predict the manner in which the people did the exercise. This is the "classe" variable in the training set. You may use any of the other variables to predict with. This eport describes how I built my model, how I used cross validation, what I think the sample error is, and why I made the choices I did. I will also use the most accurate prediction model to predict 20 different test cases.

#4.Analysis

##a. Load Libraries
```{r}
library(caret)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
library(rattle)
library(randomForest)
library(knitr)
```

##b.Getting and Loading the Data
```{r}
set.seed(052789)

trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

training <- read.csv(url(trainUrl), na.strings=c("NA","#DIV/0!",""))
testing <- read.csv(url(testUrl), na.strings=c("NA","#DIV/0!",""))
```
Partioning the training set into two
```{r}
inTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)
myTraining <- training[inTrain, ]
myTesting <- training[-inTrain, ]
dim(myTraining); dim(myTesting)
```
##c. Clean the data
Remove NZV variables
```{r}
nzv <- nearZeroVar(myTraining, saveMetrics=TRUE)
myTraining <- myTraining[,nzv$nzv==FALSE]

nzv<- nearZeroVar(myTesting,saveMetrics=TRUE)
myTesting <- myTesting[,nzv$nzv==FALSE]
```
Remove the first column of the myTraining data set
```{r}
myTraining <- myTraining[c(-1)]
```
Clean variables with NA
```{r}
trainingV3 <- myTraining
for(i in 1:length(myTraining)) {
    if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {
        for(j in 1:length(trainingV3)) {
            if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {
                trainingV3 <- trainingV3[ , -j]
            }   
        } 
    }
}

myTraining <- trainingV3
rm(trainingV3)
```
Transform the data sets
```{r}
set1 <- colnames(myTraining)
set2 <- colnames(myTraining[, -58])  
myTesting <- myTesting[set1]         
testing <- testing[set2]             

dim(myTesting)
dim(testing)
```
Transform the data to the correct type
```{r}
for (i in 1:length(testing) ) {
    for(j in 1:length(myTraining)) {
        if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {
            class(testing[j]) <- class(myTraining[i])
        }      
    }      
}

# To get the same class between testing and myTraining
testing <- rbind(myTraining[2, -58] , testing)
testing <- testing[-1,]
```
##d. Decision Tree Prediction
```{r}
set.seed(052789)
DTP <- rpart(classe ~ ., data=myTraining, method="class")
fancyRpartPlot(DTP)
```
Accuracy Prediction
```{r}
predictionsDTP <- predict(DTP, myTesting, type = "class")
cmtree <- confusionMatrix(predictionsDTP, myTesting$classe)
cmtree
```
##e. Boosted Regression Prediction
```{r}
set.seed(052789)
fitControl <- trainControl(method = "repeatedcv",
                           number = 5,
                           repeats = 1)

BRP <- train(classe ~ ., data=myTraining, method = "gbm",
                 trControl = fitControl,
                 verbose = FALSE)


BRPFinMod1 <- BRP$finalModel

BRPPredTest <- predict(BRP, newdata=myTesting)
BRPAccuracyTest <- confusionMatrix(BRPPredTest, myTesting$classe)
BRPAccuracyTest
```
Plot
```{r}
plot(BRP, ylim=c(0.9, 1))
```
##f. Random Forests Prediction
```{r}
set.seed(052789)
RFP <- randomForest(classe ~ ., data=myTraining)
predictionRFP <- predict(RFP, myTesting, type = "class")
cmrf <- confusionMatrix(predictionRFP, myTesting$classe)
cmrf
```
Plot
```{r}
plot(RFP)
```
#5. Predicting Results using Test Data

```{r}
predictionB2 <- predict(RFP, testing, type = "class")
predictionB2
```
The random forest prediction gave an accuracy in the testing data set of 99.9%  The decision tree was only 87.7% and the GBM was 99.5%  The expected out of sample error is 100-99.9 or .1%


